{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-CuW-K0DA0G"
   },
   "source": [
    "# Initiation du modèle pourri à améliorer pour E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aB9s9CEFHTC9",
    "outputId": "528fef2e-2e01-44ae-9ade-bc05ec928817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 42.3 MB/s \n",
      "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
      "\u001b[K     |████████████████████████████████| 628 kB 35.3 MB/s \n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 38.1 MB/s \n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
      "\u001b[K     |████████████████████████████████| 451 kB 39.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 1.0.0\n",
      "    Uninstalling catalogue-1.0.0:\n",
      "      Successfully uninstalled catalogue-1.0.0\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 1.0.5\n",
      "    Uninstalling srsly-1.0.5:\n",
      "      Successfully uninstalled srsly-1.0.5\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 7.4.0\n",
      "    Uninstalling thinc-7.4.0:\n",
      "      Successfully uninstalled thinc-7.4.0\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 2.2.4\n",
      "    Uninstalling spacy-2.2.4:\n",
      "      Successfully uninstalled spacy-2.2.4\n",
      "Successfully installed catalogue-2.0.6 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.0 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgCj1LSM0kaK",
    "outputId": "7f1ebe6d-1f8d-4a6e-b6d7-dc9073eb21e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-lg==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.2.0/fr_core_news_lg-3.2.0-py3-none-any.whl (572.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 572.9 MB 3.1 kB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-lg==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (57.4.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (21.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (1.19.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (0.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->fr-core-news-lg==3.2.0) (2.0.1)\n",
      "Installing collected packages: fr-core-news-lg\n",
      "Successfully installed fr-core-news-lg-3.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6WiWVvADE1x",
    "outputId": "faee03c6-9fa7-46d5-9e1c-1dfbd5464058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SGh9EqRDA0s"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIRpJ0loDA0t",
    "outputId": "5ba5eafd-24cb-4c09-e40b-8409d33eefed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # Calculs matriciels\n",
    "import pandas as pd\n",
    "\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "# lemmatizer pour récupérer les racines des mots\n",
    "import json # pour obtenir des fonctions sur des objets JSON\n",
    "import pickle # Sauvegarder un objet python\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout # Éléments pour un réseau de neurones \n",
    "from tensorflow.keras.optimizers import SGD # Stochastic gradient descent il sera accéléré avec Nesterov = True\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnYXkz6sDA0u"
   },
   "source": [
    "# Initialisation de mes listes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CEv5cK2XDA0v"
   },
   "outputs": [],
   "source": [
    "words=[] # Liste des mots\n",
    "classes = [] # Liste des classes\n",
    "documents = [] # Liste des patterns + tag associé\n",
    "ignore_words = ['?', '!'] # Liste des mots à ignorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EnUKfddDA0v"
   },
   "source": [
    "# Import du fichier json\n",
    "C'est à partir de ça qu'on va créer la personnalité de notre chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KY8DfE15DA0w"
   },
   "outputs": [],
   "source": [
    "data_file = open('/content/drive/Shareddrives/P#13_Dev IA - Ecole IA Microsoft (DRIVE APPRENANTS)/P#13_ALTERNANCE/ChatBot Simplon C14/intents.json').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mnxx6k-3DA0w"
   },
   "outputs": [],
   "source": [
    "intents = json.loads(data_file) \n",
    "# récupération du fichier d'intents avec des patterns, leur tag correspondant et les \n",
    "# réponses qui leur correspondent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFOvJ1PqDA0x"
   },
   "source": [
    "<a id=\"json\"></a>\n",
    "# Découverte des éléments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ilNUq7wDA0x",
    "outputId": "f9a9b499-9e73-46df-9a60-3ac820266e26",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[{'tag': 'contact', 'patterns': ['Je peux téléphoner ?', 'numéro téléphone', 'appeler', 'appeller', 'appel', 'apel', 'apelle', \"comment avoir quelqu'un ?\", \"comment contacter quelqu'un?\", 'joindre', 'contact', 'email', 'e-mail', 'mail', 'téléphone', 'envoyer un email', 'contacter', 'responsable', 'avoir un responsable', 'chef', 'qui est respondable?', 'coordonnées'], 'responses': [\"Nous privilégions les échanges par mail, n'hésitez pas à nous joindre via le formulaire de contact : https://simplon.co/contact.html\"], 'context': ['']}, {'tag': 'Mode', 'patterns': ['Distanciel ou présentiel ?', 'Les formations sont elles disponibles en distanciel ?', 'Les formations sont elles disponibles en présentiel ?', 'Les formations sont elles disponibles en distanciel ?', 'Comment les formations sont-elle dispensées ?', 'Distance', 'Remote', 'Présence', 'formation par internet'], 'responses': [\"Les formations peuvent être en distanciel ou présentiel selon les cas. Cette information est disponible dans l'intitulé de la formation. Retrouvez les informations sur le site : https://auvergnerhonealpes.simplon.co/candidatures.html\"], 'context': ['']}, {'tag': 'Prix', 'patterns': ['Quel est le prix des formation ?', 'Prix ? ', 'Combien coûte vos formations ?', 'Quel charge pour vos formations ?', 'Combien ça coûte ?', 'Financement', 'Comment financer la formation ?', 'CPF', 'DIF'], 'responses': ['Les formations dispensées par Simplon sont entièrement gratuites pour les apprenant.e.s car elles sont financées par des acteurs publics : https://simplon.co/faq/gratuite'], 'context': ['']}, {'tag': 'Salutations', 'patterns': ['Bonjour', 'Hello', 'Hi', 'Salut', 'Greeting', 'slt', 'bjr'], 'responses': ['Bonjour, comment puis-je vous aider ?'], 'context': ['']}, {'tag': 'Formation', 'patterns': ['Quels sont les formations disponibles prochainement ?', 'Quelle est la date d’ouverture de formation ?', 'Quelles sont les formations dispensées ?', \"Qu'est ce que vous proposez comme formation ?\", 'Quelle formation vous faites ?'], 'responses': ['Pour toute question concernant les formations à venir, merci de consulter la page des formations : https://auvergnerhonealpes.simplon.co/candidatures.html'], 'context': ['']}, {'tag': 'Identite', 'patterns': [\"Qu'est-ce-que simplon ?\", 'Simplon ?', 'Puis-je avoir des informations sur Simplon ?', \"c'est quoi simplon ?\", 'Qui êtes vous ?', 'comment avoir des informations?'], 'responses': ['Vous trouverez toutes les informations sur Simplon ici : https://simplon.co/a-propos.html'], 'context': ['']}, {'tag': 'none', 'patterns': [''], 'responses': [\"Je n'ai pas compris votre question, voulez-vous des informations sur simplon ? Nos formations ?\"], 'context': ['']}]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents.values() # Aperçu du melf intents.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0UG6YJbDA02"
   },
   "source": [
    "# Remplissage des dossiers de travail\n",
    "`words`, `documents` et `classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nohlbUpbDA02"
   },
   "outputs": [],
   "source": [
    "for intent in intents['intents']: # pour chaque intent du fichier intents.json\n",
    "    for pattern in intent['patterns']: # pour chaque pattern de chaque intent du fichier\n",
    "                                        # intents.json\n",
    "\n",
    "        #tokenize each word\n",
    "        w = nltk.word_tokenize(pattern) # par exemple \"Hello there\" = [\"hello\", \"there\"]\n",
    "        words.extend(w) # Cela ajoute chaque mot tokenizé du pattern w à la liste `words`\n",
    "        #add documents in the corpus\n",
    "        documents.append((w, intent['tag'])) # Le couple w et tag sont ajoutés à la liste documents\n",
    "        # docs[] = [[\"hello\", \"there\"],'greetings']\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes: # Si le tag n'existe pas déjà, \n",
    "            classes.append(intent['tag']) # il est ajouté à la liste des tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDHIpM6TDA04",
    "outputId": "29ca854e-8e6c-4643-e5fb-f038cf058f9b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Je', 'peux', 'téléphoner', '?'], 'contact'),\n",
       " (['numéro', 'téléphone'], 'contact'),\n",
       " (['appeler'], 'contact'),\n",
       " (['appeller'], 'contact'),\n",
       " (['appel'], 'contact'),\n",
       " (['apel'], 'contact'),\n",
       " (['apelle'], 'contact'),\n",
       " (['comment', 'avoir', \"quelqu'un\", '?'], 'contact'),\n",
       " (['comment', 'contacter', \"quelqu'un\", '?'], 'contact'),\n",
       " (['joindre'], 'contact'),\n",
       " (['contact'], 'contact'),\n",
       " (['email'], 'contact'),\n",
       " (['e-mail'], 'contact'),\n",
       " (['mail'], 'contact'),\n",
       " (['téléphone'], 'contact'),\n",
       " (['envoyer', 'un', 'email'], 'contact'),\n",
       " (['contacter'], 'contact'),\n",
       " (['responsable'], 'contact'),\n",
       " (['avoir', 'un', 'responsable'], 'contact'),\n",
       " (['chef'], 'contact'),\n",
       " (['qui', 'est', 'respondable', '?'], 'contact'),\n",
       " (['coordonnées'], 'contact'),\n",
       " (['Distanciel', 'ou', 'présentiel', '?'], 'Mode'),\n",
       " (['Les',\n",
       "   'formations',\n",
       "   'sont',\n",
       "   'elles',\n",
       "   'disponibles',\n",
       "   'en',\n",
       "   'distanciel',\n",
       "   '?'],\n",
       "  'Mode'),\n",
       " (['Les',\n",
       "   'formations',\n",
       "   'sont',\n",
       "   'elles',\n",
       "   'disponibles',\n",
       "   'en',\n",
       "   'présentiel',\n",
       "   '?'],\n",
       "  'Mode'),\n",
       " (['Les',\n",
       "   'formations',\n",
       "   'sont',\n",
       "   'elles',\n",
       "   'disponibles',\n",
       "   'en',\n",
       "   'distanciel',\n",
       "   '?'],\n",
       "  'Mode'),\n",
       " (['Comment', 'les', 'formations', 'sont-elle', 'dispensées', '?'], 'Mode'),\n",
       " (['Distance'], 'Mode'),\n",
       " (['Remote'], 'Mode'),\n",
       " (['Présence'], 'Mode'),\n",
       " (['formation', 'par', 'internet'], 'Mode'),\n",
       " (['Quel', 'est', 'le', 'prix', 'des', 'formation', '?'], 'Prix'),\n",
       " (['Prix', '?'], 'Prix'),\n",
       " (['Combien', 'coûte', 'vos', 'formations', '?'], 'Prix'),\n",
       " (['Quel', 'charge', 'pour', 'vos', 'formations', '?'], 'Prix'),\n",
       " (['Combien', 'ça', 'coûte', '?'], 'Prix'),\n",
       " (['Financement'], 'Prix'),\n",
       " (['Comment', 'financer', 'la', 'formation', '?'], 'Prix'),\n",
       " (['CPF'], 'Prix'),\n",
       " (['DIF'], 'Prix'),\n",
       " (['Bonjour'], 'Salutations'),\n",
       " (['Hello'], 'Salutations'),\n",
       " (['Hi'], 'Salutations'),\n",
       " (['Salut'], 'Salutations'),\n",
       " (['Greeting'], 'Salutations'),\n",
       " (['slt'], 'Salutations'),\n",
       " (['bjr'], 'Salutations'),\n",
       " (['Quels', 'sont', 'les', 'formations', 'disponibles', 'prochainement', '?'],\n",
       "  'Formation'),\n",
       " (['Quelle',\n",
       "   'est',\n",
       "   'la',\n",
       "   'date',\n",
       "   'd',\n",
       "   '’',\n",
       "   'ouverture',\n",
       "   'de',\n",
       "   'formation',\n",
       "   '?'],\n",
       "  'Formation'),\n",
       " (['Quelles', 'sont', 'les', 'formations', 'dispensées', '?'], 'Formation'),\n",
       " ([\"Qu'est\", 'ce', 'que', 'vous', 'proposez', 'comme', 'formation', '?'],\n",
       "  'Formation'),\n",
       " (['Quelle', 'formation', 'vous', 'faites', '?'], 'Formation'),\n",
       " ([\"Qu'est-ce-que\", 'simplon', '?'], 'Identite'),\n",
       " (['Simplon', '?'], 'Identite'),\n",
       " (['Puis-je', 'avoir', 'des', 'informations', 'sur', 'Simplon', '?'],\n",
       "  'Identite'),\n",
       " ([\"c'est\", 'quoi', 'simplon', '?'], 'Identite'),\n",
       " (['Qui', 'êtes', 'vous', '?'], 'Identite'),\n",
       " (['comment', 'avoir', 'des', 'informations', '?'], 'Identite'),\n",
       " ([], 'none')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-vFSkGYqDA07"
   },
   "outputs": [],
   "source": [
    "# Je vais réutiliser ce code donc je fais une fonction:\n",
    "def display_words(display = 30):\n",
    "    print(f\"les {display} premiers mots sont {words[:display]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Kwwcep2vDA08"
   },
   "outputs": [],
   "source": [
    "# lemmaztize and lower each word and remove duplicates\n",
    "# ça c'est une boucle compactée c'est équivalent à :\n",
    "# for w in words: ## pour chaque mot de la liste words\n",
    "#     if w not in ignore_words: ## si le mot n'est pas dans la liste des mots à ignorer 'ignore_words'\n",
    "#        w = lemmatizer.lemmatize(w.lower()) # on prend la racine du mot sans majuscule\n",
    "#        words.append(w) ## on ajout w dans la liste de mots 'words'\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gYvParqDA1D",
    "outputId": "d0db5dc8-8588-4115-bae1-5f6050b31c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les 30 premiers mots sont ['apel', 'apelle', 'appel', 'appeler', 'appeller', 'avoir', 'bjr', 'bonjour', \"c'est\", 'ce', 'charge', 'chef', 'combien', 'comme', 'comment', 'contact', 'contacter', 'coordonnées', 'coûte', 'cpf', 'd', 'date', 'de', 'dif', 'dispensées', 'disponibles', 'distance', 'distanciel', 'e-mail', 'elles']\n"
     ]
    }
   ],
   "source": [
    "words = sorted(list(set(words))) # Classement des mots dans l'ordre alphabétiques sans doublons\n",
    "display_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxarHnc6DA1E",
    "outputId": "97f8bcb5-1aa9-44aa-a78c-48cf2e507898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 59 documents.\n",
      "\n",
      "Il y a 7 classes. \n",
      "composées de:\n",
      " ['Formation', 'Identite', 'Mode', 'Prix', 'Salutations', 'contact', 'none']\n",
      "\n",
      "Il y a 87 mots lemmatisés sans doublons. \n",
      "composés de :\n",
      " ['apel', 'apelle', 'appel', 'appeler', 'appeller', 'avoir', 'bjr', 'bonjour', \"c'est\", 'ce', 'charge', 'chef', 'combien', 'comme', 'comment', 'contact', 'contacter', 'coordonnées', 'coûte', 'cpf', 'd', 'date', 'de', 'dif', 'dispensées', 'disponibles', 'distance', 'distanciel', 'e-mail', 'elles', 'email', 'en', 'envoyer', 'est', 'faites', 'financement', 'financer', 'formation', 'greeting', 'hello', 'hi', 'information', 'internet', 'je', 'joindre', 'la', 'le', 'mail', 'numéro', 'ou', 'ouverture', 'par', 'peux', 'pour', 'prix', 'prochainement', 'proposez', 'présence', 'présentiel', 'puis-je', \"qu'est\", \"qu'est-ce-que\", 'que', 'quel', 'quelle', 'quelles', \"quelqu'un\", 'quels', 'qui', 'quoi', 'remote', 'respondable', 'responsable', 'salut', 'simplon', 'slt', 'sont', 'sont-elle', 'sur', 'téléphone', 'téléphoner', 'un', 'vos', 'vous', 'ça', 'êtes', '’']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On crée le bag of word\n",
    "# sort/tri classes\n",
    "classes = sorted(list(set(classes)))\n",
    "# documents = combination between patterns and intents\n",
    "print (f\"Il y a {len(documents)} documents.\\n\")\n",
    "# classes = intents\n",
    "print (f\"Il y a {len(classes)} classes. \\ncomposées de:\\n {classes}\\n\")\n",
    "# words = all words, vocabulary\n",
    "print (f\"Il y a {len(words)} mots lemmatisés sans doublons. \\ncomposés de :\\n {words}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qOqR9HuaDA1F"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-38c207c222c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# On exporte les dictionnaires\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'words.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'classes.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "# On exporte les dictionnaires\n",
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFK1YeWwhjh7",
    "outputId": "5385739d-9a96-4934-baf9-dc344d195b7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['je', 'peux', 'téléphoner']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lemmatizer.lemmatize(word.lower()) for word in documents[0][0] if word not in ignore_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zI2gfx0XKrj6"
   },
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7LRTTNcxvSH",
    "outputId": "c7897363-c972-434d-cccd-34d4613b5a1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "oqS95S1HyGK_",
    "outputId": "a6a01181-cfa7-4565-a4a9-70a3f196972a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'contact'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORqSmx-HDA1L",
    "outputId": "a95bd5d4-f757-4c71-f263-583cc85d70e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "# create our training data\n",
    "training = [] # Ce sera la liste de données d'entraînement\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes) # -> [0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
    "                                # matrice qui identifiera le tag avec un nombre '1'\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents: # pour chaque association pattern + tag dans la liste \n",
    "                        # documents\n",
    "    # un doc ressemble à : [['hi', 'there'], 'greeting']\n",
    "                            # pattern , tag\n",
    "                            # partie 0 , partie 1\n",
    "                            # pattern , tag\n",
    "    \n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0] # récupération de la partie pattern d'un élément\n",
    "                            # de la liste documents\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    # chaque mot du pattern est mis en minuscule et on ne prend que la racine\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "\n",
    "    # create our bag of words array with 1, if word match found in current pattern    \n",
    "     # INITIALISE LE SAC DE MOTS\n",
    "    bag = [] # sac de mots ce sera un vecteur avec un 1 pour chaque mot \n",
    "    #présent dans le pattern à la position du mots dans words. \n",
    "    # Donc à la fin on aura un vecteur de 88 chiffres.\n",
    "    \n",
    "    # REMPLISSAGE DU SAC DE MOT\n",
    "    # On va comparer les mots de du pattern avec les mots de 'words'\n",
    "    for w in words: # Pour chaque mot de la liste 'words'\n",
    "        # La ligne qui suit est équivalente à :\n",
    "        # if w in pattern_words: ## Si le mot du pattern est dans 'words'\n",
    "        #    bag.append(1) ## on ajoute 1 à bag\n",
    "        # else:            ## sinon\n",
    "        #    bag.append(0) ## on ajoute un 0\n",
    "        bag.append(1) if w in pattern_words else bag.append(0) \n",
    "        # Comme il y a 88 mots dans le dictionnaire,\n",
    "        # on obtient une matrice de 88 '0' et '1' avec un '1' à la position\n",
    "        # de chaque mot présent.\n",
    "        # Par exemple si 'hello' et 'there' ont la position 1 et 2 dans 'words'\n",
    "        #  on obtient le vecteur [1,1,0,0,...,0] un \n",
    "    \n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    # on est toujours dans la boucle doc in documents donc on repart d'un\n",
    "    # vecteur vierge pour vectoriser le tag (doc[1]) (rappel la forme de doc)\n",
    "    output_row = list(output_empty) \n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    training.append([bag, output_row]) \n",
    "    # le doc vectorisé est ajouté au training\n",
    "    # par exemple [[1,1,0,0,..,0,0][1, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training) # on mélange les data d'entraînement\n",
    "training = np.array(training) # on met training sous forme de tableau numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UlvjFBkEDA1O",
    "outputId": "0c3e44e5-03f1-4767-84b3-8a9ac2a3d2aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       "       list([0, 0, 0, 0, 0, 1, 0])], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[0] # affichage du  premier élément du traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WC-5P1QzDA1P",
    "outputId": "395b143b-4c91-41b8-dd61-748d630e0429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n"
     ]
    }
   ],
   "source": [
    "# create train and test lists. X - patterns, Y - intents\n",
    "train_x = list(training[:,0]) # on crée les données avec la colonne 0 (patterns)\n",
    "train_y = list(training[:,1]) # on crée la target avec la colonne 1 (les tag)\n",
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "re0NVwec5OTp",
    "outputId": "a3cfa1e1-4945-421b-eaf3-4602dedaee22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8erFsXh5P3R",
    "outputId": "c71127f3-db44-4fe8-d56d-a422a983f97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               11264     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,975\n",
      "Trainable params: 19,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeDAToGoDA1S",
    "outputId": "53a32969-d2f3-4a74-fd94-b9da6acec0f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 2s 4ms/step - loss: 1.9439 - accuracy: 0.2542\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8075 - accuracy: 0.3898\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7206 - accuracy: 0.4068\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6286 - accuracy: 0.4237\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.5218 - accuracy: 0.4746\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4183 - accuracy: 0.4915\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.4588 - accuracy: 0.4915\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.3373 - accuracy: 0.5085\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2683 - accuracy: 0.6102\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.1345 - accuracy: 0.6271\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1232 - accuracy: 0.6102\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.9381 - accuracy: 0.7119\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.8950 - accuracy: 0.7119\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.9660 - accuracy: 0.7119\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.9623 - accuracy: 0.6780\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.8562 - accuracy: 0.7288\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7575 - accuracy: 0.7627\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7147 - accuracy: 0.7627\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7283 - accuracy: 0.7797\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.8475\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.8644\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.9153\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.9322\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.9322\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.9153\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.9492\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.9661\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.9322\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.9153\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.9322\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.9492\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2380 - accuracy: 0.9492\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2415 - accuracy: 0.9492\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.9322\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1963 - accuracy: 0.9492\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9492\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1773 - accuracy: 0.9831\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2610 - accuracy: 0.9322\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9831\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2189 - accuracy: 0.9492\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2417 - accuracy: 0.9153\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9831\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2076 - accuracy: 0.9492\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1966 - accuracy: 0.9661\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1480 - accuracy: 0.9492\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1568 - accuracy: 0.9661\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2305 - accuracy: 0.9492\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9661\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1937 - accuracy: 0.9661\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2129 - accuracy: 0.9492\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.9492\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1767 - accuracy: 0.9661\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2145 - accuracy: 0.9492\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1399 - accuracy: 0.9492\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1590 - accuracy: 0.9492\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9831\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.9831\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9661\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9831\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9831\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9831\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9661\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9492\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9661\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9661\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9831\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.9661\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1510 - accuracy: 0.9661\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9831\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9661\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1153 - accuracy: 0.9661\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9661\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.9831\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9831\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9831\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9831\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9831\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9661\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.9661\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9831\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9831\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1057 - accuracy: 0.9661\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9831\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9322\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9661\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9661\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9831\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9661\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0787 - accuracy: 0.9831\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9831\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9831\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9831\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9661\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9661\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9831\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0935 - accuracy: 0.9661\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9831\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9661\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9831\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9831\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9831\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9831\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0386 - accuracy: 0.9831\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9492\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9831\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9661\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9831\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9831\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9831\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9831\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9831\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9831\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9661\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9831\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9661\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9831\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0403 - accuracy: 0.9831\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.9831\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9831\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9661\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9831\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9831\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9661\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9831\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9831\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9831\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9831\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9661\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9831\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9831\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9661\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9831\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9831\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9831\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9831\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9831\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9831\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9831\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9831\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9831\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9831\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9661\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9831\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9831\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9831\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9831\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9831\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9831\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "# Create model - \n",
    "# 3 couches dense + un input\n",
    "# input avec 88 neurones puisque les données d'entrées font la taille de words\n",
    "# un neurone par mot de words\n",
    "# une couche de 128 (par exemple) et une couche de (64)\n",
    "# l'OUTPUT a autant de neurones que de classes et une fonction d'activation\n",
    "# softmax car c'est une classification multiclasse\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "#fitting and saving the model \n",
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
    "model.save('chatbot_model.h5', hist) # sauvegarde du model pour pouvoir\n",
    "# l'utiliser ailleurs sans avoir à relancer tout ce script\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHaEukeCDA1T"
   },
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "T3E_nd0TDA1T"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('chatbot_model.h5')\n",
    "import json\n",
    "import random\n",
    "intents = json.loads(open('../data/intents.json').read()) \n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rAbwWGXeDA1U"
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    '''\n",
    "    Nettoie une phrase en la tokenisant et lemmatisant\n",
    "    '''\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amOO8mWfDA1V",
    "outputId": "5bf81d14-42be-4f51-87ca-7adfb5646d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = [0]*9\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2vJk4XqDA1W",
    "outputId": "9c3178c7-8084-498e-d237-1440e27ee35c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag[5] = 1\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Godc0RQBDA1X",
    "outputId": "73d4468f-4252-4d0a-8e7e-136ae31cd143",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'indice c'est : 0 et le mot c'est : apel\n",
      "L'indice c'est : 1 et le mot c'est : apelle\n",
      "L'indice c'est : 2 et le mot c'est : appel\n",
      "L'indice c'est : 3 et le mot c'est : appeler\n",
      "L'indice c'est : 4 et le mot c'est : appeller\n",
      "L'indice c'est : 5 et le mot c'est : avoir\n",
      "L'indice c'est : 6 et le mot c'est : bjr\n",
      "L'indice c'est : 7 et le mot c'est : bonjour\n",
      "L'indice c'est : 8 et le mot c'est : c'est\n",
      "L'indice c'est : 9 et le mot c'est : ce\n",
      "L'indice c'est : 10 et le mot c'est : charge\n",
      "L'indice c'est : 11 et le mot c'est : chef\n",
      "L'indice c'est : 12 et le mot c'est : combien\n",
      "L'indice c'est : 13 et le mot c'est : comme\n",
      "L'indice c'est : 14 et le mot c'est : comment\n",
      "L'indice c'est : 15 et le mot c'est : contact\n",
      "L'indice c'est : 16 et le mot c'est : contacter\n",
      "L'indice c'est : 17 et le mot c'est : coordonnées\n",
      "L'indice c'est : 18 et le mot c'est : coûte\n",
      "L'indice c'est : 19 et le mot c'est : cpf\n",
      "L'indice c'est : 20 et le mot c'est : d\n",
      "L'indice c'est : 21 et le mot c'est : date\n",
      "L'indice c'est : 22 et le mot c'est : de\n",
      "L'indice c'est : 23 et le mot c'est : dif\n",
      "L'indice c'est : 24 et le mot c'est : dispensées\n",
      "L'indice c'est : 25 et le mot c'est : disponibles\n",
      "L'indice c'est : 26 et le mot c'est : distance\n",
      "L'indice c'est : 27 et le mot c'est : distanciel\n",
      "L'indice c'est : 28 et le mot c'est : e-mail\n",
      "L'indice c'est : 29 et le mot c'est : elles\n",
      "L'indice c'est : 30 et le mot c'est : email\n",
      "L'indice c'est : 31 et le mot c'est : en\n",
      "L'indice c'est : 32 et le mot c'est : envoyer\n",
      "L'indice c'est : 33 et le mot c'est : est\n",
      "L'indice c'est : 34 et le mot c'est : faites\n",
      "L'indice c'est : 35 et le mot c'est : financement\n",
      "L'indice c'est : 36 et le mot c'est : financer\n",
      "L'indice c'est : 37 et le mot c'est : formation\n",
      "L'indice c'est : 38 et le mot c'est : greeting\n",
      "L'indice c'est : 39 et le mot c'est : hello\n",
      "L'indice c'est : 40 et le mot c'est : hi\n",
      "L'indice c'est : 41 et le mot c'est : information\n",
      "L'indice c'est : 42 et le mot c'est : internet\n",
      "L'indice c'est : 43 et le mot c'est : je\n",
      "L'indice c'est : 44 et le mot c'est : joindre\n",
      "L'indice c'est : 45 et le mot c'est : la\n",
      "L'indice c'est : 46 et le mot c'est : le\n",
      "L'indice c'est : 47 et le mot c'est : mail\n",
      "L'indice c'est : 48 et le mot c'est : numéro\n",
      "L'indice c'est : 49 et le mot c'est : ou\n",
      "L'indice c'est : 50 et le mot c'est : ouverture\n",
      "L'indice c'est : 51 et le mot c'est : par\n",
      "L'indice c'est : 52 et le mot c'est : peux\n",
      "L'indice c'est : 53 et le mot c'est : pour\n",
      "L'indice c'est : 54 et le mot c'est : prix\n",
      "L'indice c'est : 55 et le mot c'est : prochainement\n",
      "L'indice c'est : 56 et le mot c'est : proposez\n",
      "L'indice c'est : 57 et le mot c'est : présence\n",
      "L'indice c'est : 58 et le mot c'est : présentiel\n",
      "L'indice c'est : 59 et le mot c'est : puis-je\n",
      "L'indice c'est : 60 et le mot c'est : qu'est\n",
      "L'indice c'est : 61 et le mot c'est : qu'est-ce-que\n",
      "L'indice c'est : 62 et le mot c'est : que\n",
      "L'indice c'est : 63 et le mot c'est : quel\n",
      "L'indice c'est : 64 et le mot c'est : quelle\n",
      "L'indice c'est : 65 et le mot c'est : quelles\n",
      "L'indice c'est : 66 et le mot c'est : quelqu'un\n",
      "L'indice c'est : 67 et le mot c'est : quels\n",
      "L'indice c'est : 68 et le mot c'est : qui\n",
      "L'indice c'est : 69 et le mot c'est : quoi\n",
      "L'indice c'est : 70 et le mot c'est : remote\n",
      "L'indice c'est : 71 et le mot c'est : respondable\n",
      "L'indice c'est : 72 et le mot c'est : responsable\n",
      "L'indice c'est : 73 et le mot c'est : salut\n",
      "L'indice c'est : 74 et le mot c'est : simplon\n",
      "L'indice c'est : 75 et le mot c'est : slt\n",
      "L'indice c'est : 76 et le mot c'est : sont\n",
      "L'indice c'est : 77 et le mot c'est : sont-elle\n",
      "L'indice c'est : 78 et le mot c'est : sur\n",
      "L'indice c'est : 79 et le mot c'est : téléphone\n",
      "L'indice c'est : 80 et le mot c'est : téléphoner\n",
      "L'indice c'est : 81 et le mot c'est : un\n",
      "L'indice c'est : 82 et le mot c'est : vos\n",
      "L'indice c'est : 83 et le mot c'est : vous\n",
      "L'indice c'est : 84 et le mot c'est : ça\n",
      "L'indice c'est : 85 et le mot c'est : êtes\n",
      "L'indice c'est : 86 et le mot c'est : ’\n"
     ]
    }
   ],
   "source": [
    "for i, w in enumerate(words):\n",
    "    print (f\"L'indice c'est : {i} et le mot c'est : {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EpYJrOygDA1Y"
   },
   "outputs": [],
   "source": [
    "def bow(sentence, words, show_details=True):\n",
    "    '''\n",
    "    renvoie la phrase vectorisée ex : -> [0,0,...,0] vecteur de 88\n",
    "    '''\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)  # -> [0,0,...,0] vecteur de 88\n",
    "    for s in sentence_words: # Pour chaque mot dans la phrase\n",
    "        for i,w in enumerate(words): # pour chaque mot du dico 'words'\n",
    "            if w == s: # si le mot de ma phrase est présent dans 'words'\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1 # on récupère l'indice de ce mot dans 'words'\n",
    "                # et on met 1 à cette position dans bag\n",
    "                if show_details: # Si on a choisit l'option de montrer les détails\n",
    "                    print (f\"found in bag: {w}\")\n",
    "            else:# TODO AMELIORATION\n",
    "                # Les mots qui n'ont pas été trouvé pourraient être récupérer pour améliorer le modèle\n",
    "                # et le réntraîner avec les mots qu'il n'a pas sû reconnaître\n",
    "                pass\n",
    "    return(np.array(bag)) # retourne le sac de mots avec des 1 à la position de \n",
    "                            #chaque mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1ht3nQxQ0w2W"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-730c51b3e7e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "PXn0573y2srg"
   },
   "outputs": [],
   "source": [
    "def bow2(sentence, words, show_details=False):\n",
    "    '''\n",
    "    renvoie la phrase vectorisée ex : -> [0,0,...,0] vecteur de 88\n",
    "    '''\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)  # -> [0,0,...,0] vecteur de 88\n",
    "    for s in sentence_words: # Pour chaque mot dans la phrase\n",
    "        tmp_pourcent = -3000\n",
    "        suceed = False\n",
    "        for i,w in enumerate(words): # pour chaque mot du dico 'words'\n",
    "            if w == s: # si le mot de ma phrase est présent dans 'words'\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1 # on récupère l'indice de ce mot dans 'words'\n",
    "                #Variable de succès \n",
    "                suceed=True\n",
    "                # et on met 1 à cette position dans bag\n",
    "                if show_details: # Si on a choisit l'option de montrer les détails\n",
    "                    print (f\"found in bag: {w}\")\n",
    "        #Si le mot n'a pas été trouvé on va cherché a trouvé une similarité grace à spacy et la fonction similarity\n",
    "        if suceed == False:\n",
    "              print(f\"{s} le mot n'a pas été trouvé recour à Spacy\")\n",
    "              #On stock le mot dans une variable spécial de Spacy\n",
    "              mots = nlp(s)\n",
    "              #On va parcourir chacuns des mots de notre dictionnaire\n",
    "              for a,b in enumerate(words):\n",
    "                #On stock de façon temporaire le mot en cours \n",
    "                atmp = nlp(b)\n",
    "                #On stock un pourcentage de similarité du mot en cours et le mot de chaque dictionnaire\n",
    "                pourcent = mots.similarity(atmp)\n",
    "                #On check et on ne garde que le plus haut pourcentage de similarité\n",
    "                if pourcent > tmp_pourcent:\n",
    "                  tmp_pourcent = pourcent\n",
    "                  #On stock la clé \n",
    "                  key = a\n",
    "                  #On stock la valeur cible\n",
    "                  value = b\n",
    "              #Si le pourcentage dépasse un seuil de similarity acceptable on garde le mot\n",
    "              if tmp_pourcent > 0.55:\n",
    "                bag[key] = 1\n",
    "                if show_details:\n",
    "                  print (f'{b} a été remplacer par{value} with {tmp_pourcent} %')\n",
    "              else :\n",
    "                print(f\"Le mot n'a pas été trouvé le plus proche est {value} with {tmp_pourcent} %\")\n",
    "              # TODO AMELIORATION\n",
    "                # Les mots qui n'ont pas été trouvé pourraient être récupérer pour améliorer le modèle\n",
    "                # et le réntraîner avec les mots qu'il n'a pas sû reconnaître\n",
    "                pass\n",
    "    return(np.array(bag)) # retourne le sac de mots avec des 1 à la position de \n",
    "                            #chaque mot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXfBEcLrDA1Z"
   },
   "source": [
    "bow renvoie ça :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gYrkr9XDA1Z",
    "outputId": "81e3151a-ea59-4a0c-b804-4de28010da79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: salut\n",
      "found in bag: quel\n",
      "found in bag: vous\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow(\"Salut quel éducation proposé vous chien\", words,show_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NnGviqv4u59",
    "outputId": "e0ad0476-f863-4107-bd36-21329d8f56d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: salut\n",
      "found in bag: quel\n",
      "éducation le mot n'a pas été trouvé recour à Spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’ a été remplacer parformation with 0.8044016542835298 %\n",
      "proposé le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parproposez with 0.6464751165428052 %\n",
      "found in bag: vous\n",
      "chien le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est quelqu'un with 0.3153063095576261 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow2(\"Salut quel éducation proposé vous chien\", words,show_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WKeAo2zDA1a",
    "outputId": "5c03b72a-99a2-42f6-e588-924cec89ba05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00425617, 0.02402028, 0.0184801 , 0.12047875, 0.04817605,\n",
       "        0.02936842, 0.75522023]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = model.predict(np.array([bow(\"Bonnjour!\", words,show_details=True)]))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b0btWwMAoH3",
    "outputId": "1078abc5-a114-440e-d9be-89ca21a5859a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonnjour le mot n'a pas été trouvé recour à Spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le mot n'a pas été trouvé le plus proche est apel with 0.0 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00425617, 0.02402028, 0.0184801 , 0.12047875, 0.04817605,\n",
       "        0.02936842, 0.75522023]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = model.predict(np.array([bow2(\"Bonnjour\", words,show_details=True)]))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xp0OHOxODA1b",
    "outputId": "ff875ac0-fd61-4133-d757-5a53c30d7645",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.predict(np.array([bow(\"Salut!\", words,show_details=False)]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gtQvUgtuDA1b"
   },
   "outputs": [],
   "source": [
    "results = [[i,r] for i,r in enumerate(test[0]) if r>0.000005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk0y9uxhaSQE",
    "outputId": "1c0a4b0f-891d-4011-c76d-59632b544e4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.0042561693],\n",
       " [1, 0.024020284],\n",
       " [2, 0.018480103],\n",
       " [3, 0.12047875],\n",
       " [4, 0.04817605],\n",
       " [5, 0.029368423],\n",
       " [6, 0.75522023]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgmeH57iDA1c",
    "outputId": "55c3b61c-640c-4bf3-cbed-d699247d91fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([4]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(np.array([bow('bonjour',words,show_details=False)]))\n",
    "vmax = result.max()\n",
    "np.where(result == vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Kb6-GfckDA1d"
   },
   "outputs": [],
   "source": [
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0] # Récupère les probabilités des 9 tags\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD ]\n",
    "    # results est les  proba qui sont supérieures au seuil \n",
    "    \n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True) \n",
    "    # triés du plus grand au plus petit\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "c1cPl4DHbp7c"
   },
   "outputs": [],
   "source": [
    "def predict_class_boost(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow2(sentence, words,show_details=True)\n",
    "    res = model.predict(np.array([p]))[0] # Récupère les probabilités des 9 tags\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD ]\n",
    "    # results est les  proba qui sont supérieures au seuil \n",
    "    \n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True) \n",
    "    # triés du plus grand au plus petit\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2j3Are8MAoN"
   },
   "source": [
    "# Test Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4sqmABiDA1e",
    "outputId": "e0f82d76-4f45-4157-a6f4-0bd4e1b30937",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'intent': 'none', 'probability': '0.75522023'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class('distenciel', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EDvEZRoGDA1f",
    "outputId": "5944ec6c-fbf2-4bcf-ad27-a5c7f09aae0e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Salutations'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXrIZ-ywRfdh"
   },
   "source": [
    "# Création d'un Dataset de test\n",
    "Pour comparer les résultats du modèle \"pourri\" avec le modèle contenant Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "KUYMBVstRdbn",
    "outputId": "c03b3daf-d0f6-4f89-cf9d-e8c5d61dcfc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contact</td>\n",
       "      <td>Comment puis-je vous contacter ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mode</td>\n",
       "      <td>Le distanciel est il possible ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prix</td>\n",
       "      <td>Quel sont vos tarif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salutations</td>\n",
       "      <td>Bonjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Formation</td>\n",
       "      <td>Quel education proposé vous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Identite</td>\n",
       "      <td>Qui es tu ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>chien chat emma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>contact</td>\n",
       "      <td>Quel est votre numéro de téléphone ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mode</td>\n",
       "      <td>Faut il être en présentiel  ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prix</td>\n",
       "      <td>Combien coûte une formation ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Salutations</td>\n",
       "      <td>Bonsoir, comment allez vous ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Formation</td>\n",
       "      <td>Quel cycle proposez vous  ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Identite</td>\n",
       "      <td>Simplon c'est quoi ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>none</td>\n",
       "      <td>J'aime manger du chien au curry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>contact</td>\n",
       "      <td>existe une adresse mail ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mode</td>\n",
       "      <td>Puis-je faire la formation en ligne ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Prix</td>\n",
       "      <td>la formation est-elle gratuite  ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Salutations</td>\n",
       "      <td>Coucou !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Formation</td>\n",
       "      <td>avez vous une formation disponible sur Lyon ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Identite</td>\n",
       "      <td>Salut t'es qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>none</td>\n",
       "      <td>afafafaegerzhfvd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        intents                                            test\n",
       "0       contact                Comment puis-je vous contacter ?\n",
       "1          Mode                Le distanciel est il possible ? \n",
       "2          Prix                             Quel sont vos tarif\n",
       "3   Salutations                                         Bonjour\n",
       "4     Formation                     Quel education proposé vous\n",
       "5      Identite                                    Qui es tu ? \n",
       "6          none                                chien chat emma \n",
       "7       contact           Quel est votre numéro de téléphone ? \n",
       "8          Mode                   Faut il être en présentiel  ?\n",
       "9          Prix                  Combien coûte une formation ? \n",
       "10  Salutations                  Bonsoir, comment allez vous ? \n",
       "11    Formation                     Quel cycle proposez vous  ?\n",
       "12     Identite                           Simplon c'est quoi ? \n",
       "13         none                J'aime manger du chien au curry \n",
       "14      contact                      existe une adresse mail ? \n",
       "15         Mode          Puis-je faire la formation en ligne ? \n",
       "16         Prix               la formation est-elle gratuite  ?\n",
       "17  Salutations                                        Coucou !\n",
       "18    Formation  avez vous une formation disponible sur Lyon ? \n",
       "19     Identite                               Salut t'es qui ? \n",
       "20         none                                afafafaegerzhfvd"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"/content/drive/Shareddrives/P#13_Dev IA - Ecole IA Microsoft (DRIVE APPRENANTS)/P#13_ALTERNANCE/ChatBot Simplon C14/Test_model.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "po-SIb_VWIQB"
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in df_test.test:\n",
    "  tmp = predict_class(i, model)\n",
    "  result.append(tmp)\n",
    "\n",
    "intent = []\n",
    "for i,z in enumerate(result):\n",
    "  intent.append(result[i][0]['intent'])\n",
    "df_test['result_bow_classique']= intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbYBuBP6W7_h",
    "outputId": "1a8e0ca6-6394-4c18-eb4d-cba475e7d961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: comment\n",
      "found in bag: puis-je\n",
      "found in bag: vous\n",
      "found in bag: contacter\n",
      "? le mot n'a pas été trouvé recour à Spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "found in bag: le\n",
      "found in bag: distanciel\n",
      "found in bag: est\n",
      "il le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est qu'est with 0.4646925417796394 %\n",
      "possible le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parpour with 0.6205444783196559 %\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "found in bag: quel\n",
      "found in bag: sont\n",
      "found in bag: vos\n",
      "tarif le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parprix with 0.7057829793620415 %\n",
      "found in bag: bonjour\n",
      "found in bag: quel\n",
      "education le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parformation with 0.755679907528988 %\n",
      "proposé le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parproposez with 0.6464751165428052 %\n",
      "found in bag: vous\n",
      "found in bag: qui\n",
      "e le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est d with 0.3074970697757877 %\n",
      "tu le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parje with 0.6257621460776422 %\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "chien le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est quelqu'un with 0.3153063095576261 %\n",
      "chat le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est téléphone with 0.40787528521372324 %\n",
      "emma le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est slt with 0.43496589504325606 %\n",
      "found in bag: quel\n",
      "found in bag: est\n",
      "votre le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parvous with 0.6974091084297114 %\n",
      "found in bag: numéro\n",
      "found in bag: de\n",
      "found in bag: téléphone\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "faut le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parpeux with 0.6793786379306935 %\n",
      "il le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est qu'est with 0.4646925417796394 %\n",
      "être le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer paravoir with 0.7048387032847507 %\n",
      "found in bag: en\n",
      "found in bag: présentiel\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "found in bag: combien\n",
      "found in bag: coûte\n",
      "une le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parla with 0.6724993460036205 %\n",
      "found in bag: formation\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "bonsoir le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parbonjour with 0.8839443353484596 %\n",
      ", le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parcomme with 0.6073008102895237 %\n",
      "found in bag: comment\n",
      "allez le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parpeux with 0.5998691910994137 %\n",
      "found in bag: vous\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "found in bag: quel\n",
      "cycle le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est formation with 0.40242520485622685 %\n",
      "found in bag: proposez\n",
      "found in bag: vous\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "found in bag: simplon\n",
      "found in bag: c'est\n",
      "found in bag: quoi\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "j'aime le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parje with 0.6364566522955887 %\n",
      "manger le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est joindre with 0.4063496530280773 %\n",
      "du le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parle with 0.654576086542068 %\n",
      "chien le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est quelqu'un with 0.3153063095576261 %\n",
      "au le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est le with 0.545946875350966 %\n",
      "curry le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est je with 0.19804529132105955 %\n",
      "existe le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est disponibles with 0.46134841709954866 %\n",
      "une le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parla with 0.6724993460036205 %\n",
      "adresse le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parinformation with 0.5779175743152938 %\n",
      "found in bag: mail\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "found in bag: puis-je\n",
      "faire le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parjoindre with 0.6449497237600839 %\n",
      "found in bag: la\n",
      "found in bag: formation\n",
      "found in bag: en\n",
      "ligne le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est internet with 0.5330705439102893 %\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "found in bag: la\n",
      "found in bag: formation\n",
      "est-elle le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est apel with 0.0 %\n",
      "gratuite le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est internet with 0.5301733796309214 %\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "coucou le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parbonjour with 0.7235198141337206 %\n",
      "! le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ça with 0.4653251565794888 %\n",
      "avez le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est êtes with 0.5430351501690205 %\n",
      "found in bag: vous\n",
      "une le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer parla with 0.6724993460036205 %\n",
      "found in bag: formation\n",
      "disponible le mot n'a pas été trouvé recour à Spacy\n",
      "’ a été remplacer pardisponibles with 0.7833682945639389 %\n",
      "found in bag: sur\n",
      "lyon le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est bonjour with 0.2582624187267779 %\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "found in bag: salut\n",
      "t'es le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est peux with 0.39690584023947456 %\n",
      "found in bag: qui\n",
      "? le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est ou with 0.3537732031277698 %\n",
      "afafafaegerzhfvd le mot n'a pas été trouvé recour à Spacy\n",
      "Le mot n'a pas été trouvé le plus proche est apel with 0.0 %\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in df_test.test:\n",
    "  tmp = predict_class_boost(i, model)\n",
    "  result.append(tmp)\n",
    "\n",
    "intent = []\n",
    "for i,z in enumerate(result):\n",
    "  intent.append(result[i][0]['intent'])\n",
    "df_test['result_bow_boosted']= intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "id": "EUJIpvhHbfae",
    "outputId": "77beabd6-6484-4e1c-8ca2-2041d91891be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "      <th>test</th>\n",
       "      <th>result_bow_classique</th>\n",
       "      <th>result_bow_boosted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contact</td>\n",
       "      <td>Comment puis-je vous contacter ?</td>\n",
       "      <td>contact</td>\n",
       "      <td>contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mode</td>\n",
       "      <td>Le distanciel est il possible ?</td>\n",
       "      <td>Mode</td>\n",
       "      <td>Mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prix</td>\n",
       "      <td>Quel sont vos tarif</td>\n",
       "      <td>Prix</td>\n",
       "      <td>Prix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salutations</td>\n",
       "      <td>Bonjour</td>\n",
       "      <td>Salutations</td>\n",
       "      <td>Salutations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Formation</td>\n",
       "      <td>Quel education proposé vous</td>\n",
       "      <td>Prix</td>\n",
       "      <td>Formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Identite</td>\n",
       "      <td>Qui es tu ?</td>\n",
       "      <td>contact</td>\n",
       "      <td>contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>chien chat emma</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>contact</td>\n",
       "      <td>Quel est votre numéro de téléphone ?</td>\n",
       "      <td>contact</td>\n",
       "      <td>contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mode</td>\n",
       "      <td>Faut il être en présentiel  ?</td>\n",
       "      <td>Mode</td>\n",
       "      <td>Mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prix</td>\n",
       "      <td>Combien coûte une formation ?</td>\n",
       "      <td>Prix</td>\n",
       "      <td>Prix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Salutations</td>\n",
       "      <td>Bonsoir, comment allez vous ?</td>\n",
       "      <td>Identite</td>\n",
       "      <td>Salutations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Formation</td>\n",
       "      <td>Quel cycle proposez vous  ?</td>\n",
       "      <td>Prix</td>\n",
       "      <td>Prix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Identite</td>\n",
       "      <td>Simplon c'est quoi ?</td>\n",
       "      <td>Identite</td>\n",
       "      <td>Identite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>none</td>\n",
       "      <td>J'aime manger du chien au curry</td>\n",
       "      <td>none</td>\n",
       "      <td>contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>contact</td>\n",
       "      <td>existe une adresse mail ?</td>\n",
       "      <td>contact</td>\n",
       "      <td>contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mode</td>\n",
       "      <td>Puis-je faire la formation en ligne ?</td>\n",
       "      <td>Prix</td>\n",
       "      <td>Prix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Prix</td>\n",
       "      <td>la formation est-elle gratuite  ?</td>\n",
       "      <td>Prix</td>\n",
       "      <td>Prix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Salutations</td>\n",
       "      <td>Coucou !</td>\n",
       "      <td>none</td>\n",
       "      <td>Salutations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Formation</td>\n",
       "      <td>avez vous une formation disponible sur Lyon ?</td>\n",
       "      <td>Formation</td>\n",
       "      <td>Formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Identite</td>\n",
       "      <td>Salut t'es qui ?</td>\n",
       "      <td>Salutations</td>\n",
       "      <td>Salutations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>none</td>\n",
       "      <td>afafafaegerzhfvd</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        intents  ... result_bow_boosted\n",
       "0       contact  ...            contact\n",
       "1          Mode  ...               Mode\n",
       "2          Prix  ...               Prix\n",
       "3   Salutations  ...        Salutations\n",
       "4     Formation  ...          Formation\n",
       "5      Identite  ...            contact\n",
       "6          none  ...               none\n",
       "7       contact  ...            contact\n",
       "8          Mode  ...               Mode\n",
       "9          Prix  ...               Prix\n",
       "10  Salutations  ...        Salutations\n",
       "11    Formation  ...               Prix\n",
       "12     Identite  ...           Identite\n",
       "13         none  ...            contact\n",
       "14      contact  ...            contact\n",
       "15         Mode  ...               Prix\n",
       "16         Prix  ...               Prix\n",
       "17  Salutations  ...        Salutations\n",
       "18    Formation  ...          Formation\n",
       "19     Identite  ...        Salutations\n",
       "20         none  ...               none\n",
       "\n",
       "[21 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG59wZiULRsH"
   },
   "source": [
    "### GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aQo0IrJ6DA1g"
   },
   "outputs": [],
   "source": [
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UJ0C612ODA1h"
   },
   "outputs": [],
   "source": [
    "def chatbot_response(msg):\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UCeXPWJhDA1h"
   },
   "outputs": [],
   "source": [
    "#Creating GUI with tkinter\n",
    "import tkinter # librairie d'interface graphique\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "7aOrOrE5DA1i",
    "outputId": "cdb1b7aa-0931-4452-baae-87c0fb821751"
   },
   "outputs": [],
   "source": [
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
    "    \n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"Bot: \" + res + '\\n\\n')\n",
    "            \n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    " \n",
    "\n",
    "base = Tk()\n",
    "base.title(\"Hello\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width=FALSE, height=FALSE)\n",
    "\n",
    "#Create Chat window\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n",
    "\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "#Bind scrollbar to Chat window\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "#Create Button to send message\n",
    "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
    "                    command= send )\n",
    "\n",
    "#Create the box to enter message\n",
    "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
    "#EntryBox.bind(\"<Return>\", send)\n",
    "\n",
    "\n",
    "#Place all components on the screen\n",
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatLog.place(x=6,y=6, height=386, width=370)\n",
    "EntryBox.place(x=128, y=401, height=90, width=265)\n",
    "SendButton.place(x=6, y=401, height=90)\n",
    "\n",
    "base.mainloop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "modele_pourri.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
